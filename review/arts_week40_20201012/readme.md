

整理如下文章: 
https://mp.weixin.qq.com/s/Abb2muE0GaVRYswqwxfJCw    


# redis常见延迟问题定位与分析  

## 使用复杂度高的命令 

```shell
# 命令执行超过5毫秒记录慢日志
CONFIG SET slowlog-log-slower-than 5000
# 只保留最近1000条慢日志
CONFIG SET slowlog-max-len 1000
# 查询最近5条慢日志
SLOWLOG get5
```

> 解决方案： 不使用复杂度较高的命令（如sort、sunion、zunionstore），并且一次不要获取太多的数据，每次尽量操作少量的数据，让Redis可以及时处理返回

##  存储大key

```shell
# 控制扫描的频率（单位：秒），防止redis qps突增
redis-cli -h $host -p $port --bigkeys -i 0.01
```

> 原理： Redis在内部执行scan命令，遍历所有key，然后针对不同类型的key执行strlen、llen、hlen、scard、zcard
来获取字符串的长度以及容器类型(list/dict/set/zset)的元素个数。对于容器类型的key，只能扫描出元素最多的key，但元素最多的key不一定占用内存最多

> 解决方案： 不建议使用大key，大key在集群的迁移过程中，也会影响到迁移的性能

## 集中过期  

### redis过期策略：  

* 主动过期  
Redis内部维护一个定时任务，默认每隔100毫秒会从过期字典中随机取出20个key，删除过期的key，如果过期key的比例超过了25%，则继续获取20个key，  
删除过期的key，循环往复，直到过期key的比例下降到25%或者这次任务的执行耗时超过了25毫秒，才会退出循环  

* 惰性过期  
只有当访问某个key时，才判断这个key是否已过期，如果已经过期，则从实例中删除

### 代码排查  

expireat，pexpireat

### 解决方案 

```shell
redis.expireat(key, expire_time + random(300))
```

### 运维

expired_keys -- 整个实例到目前为止，累计删除过期key的数量  
针对这个指标和业务报慢的时间进行对比分析  


## 实例内存达到上限  

### 淘汰策略 

* allkeys-lru：不管key是否设置了过期，淘汰最近最少访问的key
* volatile-lru：只淘汰最近最少访问并设置过期的key
* allkeys-random：不管key是否设置了过期，随机淘汰
* volatile-random：只随机淘汰有设置过期的key
* allkeys-ttl：不管key是否设置了过期，淘汰即将过期的key
* noeviction：不淘汰任何key，满容后再写入直接报错
* allkeys-lfu：不管key是否设置了过期，淘汰访问频率最低的key（4.0+支持）
* volatile-lfu：只淘汰访问频率最低的过期key（4.0+支持）
 
allkeys-xxx表示从所有的键值中淘汰数据，而volatile-xxx表示从设置了过期键的键值中淘汰数据。   
  
最常使用的一般是allkeys-lru或volatile-lru策略，它们的处理逻辑是，每次从实例中随机取出一批key（可配置），然后淘汰一个最少访问的key，  
之后把剩下的key暂存到一个池子中，继续随机取出一批key，并与之前池子中的key比较，再淘汰一个最少访问的key。以此循环，直到内存降到maxmemory之下。  

如果使用的是allkeys-random或volatile-random策略，那么就会快很多，因为是随机淘汰，那么就少了比较key访问频率时间的消耗了，  
随机拿出一批key后直接淘汰即可，因此这个策略要比上面的LRU策略执行快一些。  


### 实践
如果你的业务访问量非常大，并且必须设置maxmemory限制实例的内存上限，同时面临淘汰key导致延迟增大的的情况，要想缓解这种情况，  
除了上面说的避免存储大key、使用随机淘汰策略之外，也可以考虑拆分实例的方法来缓解，拆分实例可以把一个实例淘汰key的压力分摊到多个实例上，可以在一定程度降低延迟    


## fork耗时严重 

rdb和aof重写任务导致 

我们可以执行info命令，查看最后一次fork执行的耗时latest_fork_usec，单位微秒。这个时间就是整个实例阻塞无法处理请求的时间。  

除了因为备份的原因生成RDB之外，在主从节点第一次建立数据同步时，主节点也会生成RDB文件给从节点进行一次全量同步，这时也会对Redis产生性能影响。  

要想避免这种情况，我们需要规划好数据备份的周期，建议在从节点上执行备份，而且最好放在**低峰期**执行。如果对于丢失数据不敏感的业务，那么不建议开启AOF和AOF重写功能。  

另外，fork的耗时也与系统有关，如果把Redis部署在虚拟机上，那么这个时间也会增大。所以使用Redis时建议部署在物理机上，降低fork的影响。  

## 绑定cpu

绑定CPU的Redis，在进行数据持久化时，fork出的子进程，子进程会继承父进程的CPU使用偏好，而此时子进程会消耗大量的CPU资源进行数据持久化，  
子进程会与主进程发生CPU争抢，这也会导致主进程的CPU资源不足访问延迟增大。

部署Redis进程时，如果需要开启RDB和AOF重写机制，一定不能进行CPU绑定操作！  


## 开启aof 

aof刷盘机制： 

* appendfsync always：每次写入都刷盘，对性能影响最大，占用磁盘IO比较高，数据安全性最高
* appendfsync everysec：1秒刷一次盘，对性能影响相对较小，节点宕机时最多丢失1秒的数据（建议使用）
* appendfsync no：按照操作系统的机制刷盘，对性能影响最小，数据安全性低，节点宕机丢失数据取决于操作系统刷盘机制


## 使用swap  

如果确实使用到了Swap，要及时整理内存空间，释放出足够的内存供Redis使用，然后释放Redis的Swap，让Redis重新使用内存。  
释放Redis的Swap过程通常要重启实例，为了避免重启实例对业务的影响，一般先进行主从切换，然后释放旧主节点的Swap，重新启动服务，待数据同步完成后，再切换回主节点即可。  

### 运维
需要对Redis机器的内存和Swap使用情况进行监控，在内存不足和使用到Swap时及时报警出来，及时进行相应的处理  

## 网卡负载过高  
排查这个机器上的哪个Redis实例的流量过大占满了网络带宽，然后确认流量突增是否属于业务正常情况，如果属于那就需要及时扩容或迁移实例，避免这个机器的其他实例受到影响。  

### 运维
对机器的各项指标增加监控，包括网络流量，在达到阈值时提前报警，及时与业务确认并扩容。  


# 总结  

要想保证Redis高性能的运行，其中涉及到CPU、内存、网络，甚至磁盘的方方面面，其中还包括操作系统的相关特性的使用。  

作为开发人员，我们需要了解Redis的运行机制，例如各个命令的执行时间复杂度、数据过期策略、数据淘汰策略等，使用合理的命令，并结合业务场景进行优化。   

作为DBA运维人员，需要了解数据持久化、操作系统fork原理、Swap机制等，并对Redis的容量进行合理规划，预留足够的机器资源，对机器做好完善的监控，才能保证Redis的稳定运行。   
