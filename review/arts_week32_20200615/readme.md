
## CAP

CAP是Consistency、Availablity和Partition-tolerance的缩写。分别是指：  

1.一致性（Consistency）：每次读操作都能保证返回的是最新数据；  

2.可用性（Availablity）：任何一个没有发生故障的节点，会在合理的时间内返回一个正常的结果；  

3.分区容忍性（Partition-torlerance）：当节点间出现网络分区，照样可以提供服务。  

CAP理论指出：CAP三者只能取其二，不可兼得。其实这一点很好理解：  

首先，单机都只能保证CP  


有两个或以上节点时，当网络分区发生时，集群中两个节点不能相互通信（也就是说不能保证可用性A）。此时如果保证数据的一致性C，那么必然会有一个节点  
被标记为不可用的状态，违反了可用性A的要求，只能保证CP。  

反之，如果保证可用性A，即两个节点可以继续各自处理请求，那么由于网络不通不能同步数据，必然又会导致数据的不一致，只能保证AP。  

对于写操作来说，根据更新策略分为三种情况：  

1.同步更新：即写操作需要等待两个节点都更新成功才返回。这样的话如果一旦发生网络分区故障，写操作便不可用，牺牲了A。  

2.异步更新：即写操作直接返回，不需要等待节点更新成功，节点异步地去更新数据（FastDFS文件系统的存储节点就是用这种方式，  
写完一份数据之后立即返回结果，副本数据由同步线程写入其他同group的节点）。这种方式，牺牲了C来保证A，即无法保证数据是否更新成功，  
还有可能会由于网络故障等原因，导致数据不一致。  

3.折衷：更新部分节点成功后便返回。  

这里，先介绍一下类Dynamo系统用于控制分布式存储系统中的一致性级别的策略--NWR：  

*N：同一份数据的副本个数  

*W：写操作需要确保成功的副本个数  

*R：读操作需要读取的副本个数  

当W+R>N时，由于读写操作覆盖到的副本集肯定会有交集，读操作只要比较副本集数据的修改时间或者版本号即可选出最新的，所以系统是强一致性的；反之，当W+R<=N时是弱一致性的。   					

如：(N,W,R)=(1,1,1)为单机系统，是强一致性的；(N,W,R)=(2,1,1)位常见的master-slave模式，是弱一致性的。  

### 例子

> 如像Cassandra中的折衷型方案QUORUM，只要超过半数的节点更新成功便返回，读取时返回多副本的一致的值。然后，对于不一致的副本，可以通过read repair的方式解决。read repair：读取某条数据时，查询所有副本中的这条数据，比较数据与大多数副本的最新数据是否一致，若否，则进行一致性修复。其中，W + R > N，故而是强一致性的。

> 又如Redis的master-slave模式，更新成功一个节点即返回，其他节点异步去备份数据。这种方式只保证了最终一致性。最终一致性：相比于数据时刻保持一致的强一致性，最终一致性允许某段时间内数据不一致。但是随着时间的增长，数据最终会到达一致的状态。其中，W+R<N，所以只能保证最终一致性。

此外，N越大，数据可靠性越好，但是由于W或者R越大，读写开销越大，性能越差，所以一般需要总和考虑一致性，可用性和读写性能，设置W，R都为N/2+1。   

其实，折衷方案和异步更新的方式从本质上来说是一样的，都是损失一定的C来换取A的提高。而且，会产生'脑裂'的问题--即网络分区时节点各自处理请求，无法同步数据，当网络恢复时，导致不一致。  


## BASE 

对于大多数的非金融类互联网公司，要求并非强一致性，而是可用性和最终一致性的保证。这也是NoSQL流行于互联网应用的一大原因，相比于强一致性系统的ACID原则，它更加倾向于BASE：  

Basically Available：基本可用性，即允许分区失败，出了问题仅服务降级；

Soft-state：软状态，即允许异步；

Eventual Consistency：最终一致性，允许数据最终一致性，而不是时刻一直。


## 总结 
基本上，上面讨论的几种方式已经涵盖了大多数的分布式存储系统了。我们可以看到，这些个方案总是需要通过牺牲一部分去换取另一部分，  
总没法达到100%的CAP。选择哪种方案，依据就是在特定场景下，究竟哪些特性是更加重要的了。  
